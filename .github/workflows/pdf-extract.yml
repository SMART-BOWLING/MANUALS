name: Extract PDF Text

on: workflow_dispatch

jobs:
  extract:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install pdfplumber

      - name: Create directories
        run: mkdir -p extracted_text

      - name: Create Python script for extraction
        run: |
          cat > extract_text.py << 'EOL'
import pdfplumber
import json
import re
import glob
import os

def extract_pdf_text():
    # Создаем папку если нет
    os.makedirs('extracted_text', exist_ok=True)
    
    all_data = []
    pdf_files = glob.glob('manuals/*.pdf')
    
    print(f"Found {len(pdf_files)} PDF files")
    
    for pdf_path in pdf_files:
        filename = os.path.basename(pdf_path)
        name_without_ext = os.path.splitext(filename)[0]
        output_data = []
        
        try:
            print(f"Processing: {filename}")
            with pdfplumber.open(pdf_path) as pdf:
                # Берем только первую страницу для теста
                if pdf.pages:
                    page = pdf.pages[0]
                    text = page.extract_text()
                    if text:
                        clean_text = re.sub(r'\s+', ' ', text).strip()
                        if clean_text:
                            output_data.append({
                                'file': filename,
                                'page': 1,
                                'text': clean_text[:500] + '...' if len(clean_text) > 500 else clean_text
                            })
            
            # Сохраняем результат для каждого PDF
            if output_data:
                output_file = f'extracted_text/{name_without_ext}.json'
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                print(f'✓ Extracted {len(output_data)} segments from {filename}')
                all_data.extend(output_data)
            else:
                print(f'✗ No text found in {filename}')
                
        except Exception as e:
            print(f'✗ Error with {filename}: {str(e)}')
    
    # Сохраняем объединенные данные
    with open('manuals/manuals.json', 'w', encoding='utf-8') as f:
        json.dump(all_data, f, indent=2, ensure_ascii=False)
    
    print(f'✓ Total: {len(all_data)} text segments extracted')

if __name__ == "__main__":
    extract_pdf_text()
EOL

      - name: Run PDF text extraction
        run: python extract_text.py

      - name: Show results
        run: |
          echo "=== Extraction completed ==="
          echo "JSON files created: $(ls extracted_text/*.json 2>/dev/null | wc -l || echo 0)"
          if [ -f "manuals/manuals.json" ]; then
            echo "Total text segments: $(python -c \"import json; f=open('manuals/manuals.json'); print(len(json.load(f))); f.close()\")"
          else
            echo "manuals.json not found"
          fi
